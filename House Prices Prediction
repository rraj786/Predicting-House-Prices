{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":18275,"sourceType":"datasetVersion","datasetId":13522}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# House Prices Prediction\n### Predicting the prices of houses based on their propoerty features","metadata":{}},{"cell_type":"code","source":"# Set up notebook headers\nimport warnings\nwarnings.simplefilter(action = 'ignore', category = FutureWarning)\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\n\nimport os\n\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\nfrom sklearn.model_selection import GridSearchCV\n\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import AdaBoostRegressor\nfrom sklearn.linear_model import SGDRegressor\n\n%matplotlib inline\n%load_ext autoreload\n%autoreload 2","metadata":{"execution":{"iopub.status.busy":"2024-05-23T10:24:07.602685Z","iopub.execute_input":"2024-05-23T10:24:07.603171Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\nThe autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### Loading Raw Data\nRead in CSV files containing train and test data. The datasets are available on Kaggle, thus copy its relative paths as this notebook is linked to them.","metadata":{}},{"cell_type":"code","source":"# Store train data in dataframe \ntrain = pd.read_csv('/kaggle/input/house-prices-dataset/train.csv', index_col = 0, na_values = 'NaN', keep_default_na = False)\ntrain.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# View top 5 rows of train dataframe\ntrain.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Store test data in dataframe \ntest = pd.read_csv('/kaggle/input/house-prices-dataset/test.csv', index_col = 0, na_values = 'NaN', keep_default_na = False)\ntest.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# View top 5 rows of test dataframe\ntest.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Data Exploration\nExplore how various attributes in the dataset are related to house price and each other. Visualise any high-level trends for further analysis.","metadata":{}},{"cell_type":"markdown","source":"**Correlation Analysis**: Measure the strength of correlation for each of the numerical variables against the Sale Price.","metadata":{}},{"cell_type":"code","source":"# Consider attributes that are int64 types\ntrain_int64 = train.select_dtypes(include = ['float64', 'int64'])\nplt.figure(figsize = (6, 10))\nheatmap = sns.heatmap(train_int64.corr()[['SalePrice']].sort_values(by = 'SalePrice', ascending = False), vmin = -1, vmax = 1, annot = True, cmap = 'BrBG')\nheatmap.set_title('Correlations of attributes with Sale Price', fontdict = {'fontsize':14}, pad = 10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Data Story 1**: The distribution of sale prices is right skewed as most of the homes have a price of USD100,000-200,000, with the greatest density at around USD130,000. There is a long tail, with the upper bound at just over USD700,000. The lower bound is at USD30,000.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (10, 6))\nax = sns.distplot(train[[\"SalePrice\"]].values)\nax.set_title(\"Distribution of Sale Prices of residential homes in Ames, Iowa\")\nax.set_xlabel(\"Sale Price (USD)\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Data Story 2**: The prices fluctuate periodically between 1870 to 1950 but remains centered around a constant figure. From 1950 to the present, there is clear increase in the price with small tremors as the price changed from year to year.","metadata":{}},{"cell_type":"code","source":"ax = sns.lineplot(x = \"YearBuilt\", y = \"SalePrice\", data = train)\nax.set_title(\"Sale Price of residential homes in Ames, Iowa against their Build Year\")\nax.set_ylabel(\"Sale Price (USD)\")\nax.set_xlabel(\"Year Built\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Data Story 3**: plot a categorical against salesprice","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Data Story 4**: plot a categorical against salesprice","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Data Story 5**: Most building types have a similar median ground living area at around 1,500 ft^2 and spread, with the duplex type having a median of just under 2,000 ft^2. Single-family type dwellings have the greatest spread in living area with the lowest and highest figures. Likewise, this style also seems to be the most common as there are more homes with living areas above the upper-quartile compared to the other types.","metadata":{}},{"cell_type":"code","source":"ax = sns.boxplot(x = \"BldgType\", y = \"GrLivArea\", data = train)\nax.set_title(\"Above Grade Living Area of residential homes in Ames, Iowa against their Building Types\")\nax.set_ylabel(\"Above Grade Living Area (ft^2)\")\nax.set_xlabel(\"Building Type\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Data Story 6**: There seems to be a positive relationship between the overall quality of materials used for a home and the size of its garage. The plot shows that most homes have a quality of 6 and 7, with garage areas ranging between 400-600 ft^2 and exhibiting right-skewness.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (8, 10))\nax = sns.JointGrid(x = \"GarageArea\", y = \"OverallQual\", data = train)\nax.plot_joint(sns.kdeplot, fill = True, cmap = \"rocket\")\nax.plot_marginals(sns.histplot, bins = 20)\nax.fig.suptitle(\"Overall Quality of residential homes in Ames, Iowa against their Garage Areas\", y = 1.01)\nax.set_axis_labels(\"Garage Area (ft^2)\", \"Overall Quality\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Data Story 7**: After disregarding the outliers for 1st floor area, it is clear that the feature has a positive relationship with lot area - they increase together. The contours indicate that most 1st floor areas are between 1,000-2,000 ft^2 and the lot areas are just under 10,000 ft^2. Whilst there is some scatter along the axes extremities, the grouping in the bottom left corner supports the positive trend.","metadata":{}},{"cell_type":"code","source":"sns.set_theme(style = \"dark\")\nax = sns.scatterplot(x = \"1stFlrSF\", y = \"LotArea\", data = train, s = 5, color = \".15\")\nax = sns.histplot(x = \"1stFlrSF\", y = \"LotArea\", data = train, bins = 50, pthresh = .1, cmap = \"mako\")\nax = sns.kdeplot(x = \"1stFlrSF\", y = \"LotArea\", data = train, levels = 5, color = \"w\", linewidths = 1)\nax.set_title(\"Lot Area of residential homes in Ames, Iowa against their Ground Living Area\")\nax.set_ylabel(\"Lot Area (ft^2)\")\nax.set_xlabel(\"1st Floor Living Area (ft^2)\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Ignore outliers where lot area is greater than 50000\ntarget = train[train.LotArea < 50000]\nax = sns.scatterplot(x = \"1stFlrSF\", y = \"LotArea\", data = target, s = 5, color = \".15\")\nax = sns.histplot(x = \"1stFlrSF\", y = \"LotArea\", data = target, bins = 50, pthresh = .1, cmap = \"mako\")\nax = sns.kdeplot(x = \"1stFlrSF\", y = \"LotArea\", data = target, levels = 5, color = \"w\", linewidths = 1)\nax.set_title(\"Lot Area of residential homes in Ames, Iowa against their 1st Floor Living Area\")\nax.set_ylabel(\"Lot Area (ft^2)\")\nax.set_xlabel(\"1st Floor Living Area (ft^2)\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Process Data\nSplit the datasets into numerical and categorical variables for model creation. Some variables may also be dropped due to missing values.","metadata":{}},{"cell_type":"code","source":"def splitting(data):\n    \n    # Select data types\n    data_num = data.select_dtypes(include = ['float64', 'int64'])\n    data_cat = data.select_dtypes(include = 'object')\n    \n    return data_num, data_cat\n\n# Split datasets into numerical and categorical features\ntrain_num, train_cat = splitting(train)\ntest_num, test_cat = splitting(test)\n\n# Remove 'SalePrice' from training set\nY = train_num['SalePrice']\ntrain_num = train_num.drop('SalePrice', axis = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's gauge how many missing values are present in each column","metadata":{}},{"cell_type":"code","source":"train.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2024-05-23T10:26:12.681675Z","iopub.execute_input":"2024-05-23T10:26:12.682075Z","iopub.status.idle":"2024-05-23T10:26:12.727201Z","shell.execute_reply.started":"2024-05-23T10:26:12.682045Z","shell.execute_reply":"2024-05-23T10:26:12.726005Z"},"trusted":true},"execution_count":70,"outputs":[{"name":"stdout","text":"MSSubClass       False\nMSZoning         False\nLotFrontage      False\nLotArea          False\nStreet           False\n                 ...  \nMoSold           False\nYrSold           False\nSaleType         False\nSaleCondition    False\nSalePrice        False\nLength: 80, dtype: bool\n","output_type":"stream"}]},{"cell_type":"code","source":"def dropfeatures(data):\n    \n    # Drop columns with over 10% missing data \n    nrow = len(data.index)\n    drop = []\n    for i in data.columns:\n        if (data[i].isna().sum()/nrow) > 0.1:\n            drop.append(i)\n\n    dropped = data.drop(drop, axis = 1)\n    \n    return dropped\n\n# Drop relevant features from both numerical sets\ntrain_num = dropfeatures(train_num) \ntest_num = dropfeatures(test_num)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Feature Extraction\nCreate new features to enhance the number options for model creation.","metadata":{}},{"cell_type":"code","source":"# Find useful ratios between existing features and add them to both numerical sets\ntrain_num['LivingAgainstLotArea'] = train_num['GrLivArea'] / train_num['LotArea']\ntrain_num['AreaPerRoom'] = train_num['GrLivArea'] / train_num['TotRmsAbvGrd']\n\ntest_num['LivingAgainstLotArea'] = test_num['GrLivArea'] / test_num['LotArea']\ntest_num['AreaPerRoom'] = test_num['GrLivArea'] / test_num['TotRmsAbvGrd']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Transform data\nImpute missing values, encode categorical data, and merge all data types to create a complete dataset.","metadata":{}},{"cell_type":"code","source":"# Identify numerical features with missing values in training set\ntrain_num.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def imputing(data):\n    \n    # Create pipeline to carry out transformations\n    pipe = Pipeline([('imputer', SimpleImputer(strategy = 'mean')),\n                    ('std_scaler', StandardScaler()),\n                    ('minmax', MinMaxScaler())])\n    \n    imp = pd.DataFrame(pipe.fit_transform(data), columns = data.columns, index = data.index)\n     \n    return imp\n       \n# Transform training set    \ntrain_num_imp = imputing(train_num)\ntrain_num_imp.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Identify numerical features with missing values in testing set\ntest_num.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Transform testing set\ntest_num_imp = imputing(test_num)\ntest_num_imp.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Identify categorical features with NAs in training set\ntrain_cat.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def replaceNA(data, cols, mode):\n    \n    for i in data.columns:\n        if i in cols:\n            data[i].fillna(mode[i][0], inplace = True)\n        else:\n            data[i].fillna('None', inplace = True)\n            \n    return data\n\n# Only 'Electrical\" has no NA option in the data description and hence must be imputed\ncols = ['Electrical']\n\n# Use training modes for both datasets\ntrain_cat = replaceNA(train_cat, cols, train_cat.mode())      \n\n# Encode all features\nencoder = OneHotEncoder(sparse = False, handle_unknown = 'ignore')\ntrain_trans = encoder.fit_transform(train_cat)\ntrain_cat_enc = pd.DataFrame(train_trans, columns = encoder.get_feature_names())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Identify categorical features with NAs in testing set\ntest_cat.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# There are quite a few features that need to be imputed in the test set \ncols = ['MSZoning', 'Utilities', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'KitchenQual', 'Functional', 'SaleType']\n\n# Use training modes for both datasets\ntest_cat = replaceNA(test_cat, cols, train_cat.mode())\n\n# Encode categorical features in testing set (use same fit as training)\ntest_trans = encoder.transform(test_cat)\ntest_cat_enc = pd.DataFrame(test_trans, columns = encoder.get_feature_names())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Combine numerical and categorical data\ntrain_cat_enc = train_cat_enc.set_index(train_num_imp.index)\ntrain_merged = pd.concat([train_num_imp, train_cat_enc], axis = 1).reindex(train_num_imp.index)\n\ntest_cat_enc = test_cat_enc.set_index(test_num_imp.index)\ntest_merged = pd.concat([test_num_imp, test_cat_enc], axis = 1).reindex(test_num_imp.index)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Model Creation\nBuild and compare various regression models and then optimise their hyperparameters.","metadata":{}},{"cell_type":"markdown","source":"**Random Forest**","metadata":{}},{"cell_type":"code","source":"# Adjust hyperparameters\nparams = [{'n_estimators': [100, 150], 'max_features': [100, 150, 175, 200]}]\n\n# Train and predict using model\nrf_reg = RandomForestRegressor()\ngrid = GridSearchCV(rf_reg, params, cv = 10, scoring = 'neg_root_mean_squared_error')\ngrid.fit(train_merged, Y)\npreds = pd.DataFrame(grid.predict(test_merged), index = test_merged.index, columns = ['SalePrice'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**AdaBoost**","metadata":{}},{"cell_type":"code","source":"# Adjust hyperparameters\nparams = [{'learning_rate': [0.1, 0.5, 1.0, 2.0], 'n_estimators': [100, 150, 300, 500]}]\n\n# Train and predict using model\nab_reg = AdaBoostRegressor()\ngrid = GridSearchCV(ab_reg, params, cv = 10, scoring = 'neg_root_mean_squared_error')\ngrid.fit(train_merged, Y)\npreds = pd.DataFrame(grid.predict(test_merged), index = test_merged.index, columns = ['SalePrice'])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**SGD**","metadata":{}},{"cell_type":"code","source":"# Adjust hyperparameters\nparams = [{'alpha':[0.0001, 0.1, 0.5, 1.0, 2.0, 5.0], 'max_iter': [1000, 5000, 20000]}]\n\n# Train and predict using model\nsgd_reg = SGDRegressor()\ngrid = GridSearchCV(sgd_reg, params, cv = 10, scoring = 'neg_root_mean_squared_error')\ngrid.fit(train_merged, Y)\npreds = pd.DataFrame(grid.predict(test_merged), index = test_merged.index, columns = ['SalePrice'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}